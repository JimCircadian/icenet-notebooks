{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick hack to put us in the icenet-pipeline folder,\n",
    "# assuming it was created as per 01.cli_demonstration.ipynb\n",
    "import os\n",
    "if os.path.exists(\"02.data_and_forecasts.ipynb\"):\n",
    "    os.chdir(\"../notebook-pipeline\")\n",
    "print(\"Running in {}\".format(os.getcwd()))\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IceNet Data and Forecast Products\n",
    "\n",
    "## Context\n",
    "\n",
    "### Purpose\n",
    "The IceNet library provides the ability to download, process, train and predict from end to end via a set of command-line interfaces (CLI).\n",
    "\n",
    "Using this notebook one can understand the various data sources, intermediaries and products that arise from the [CLI demonstrator notebook](01.cli_demonstration.ipynb) activities.\n",
    "\n",
    "### Modelling approach\n",
    "This modelling approach allows users to immediately utilise the library for producing sea ice concentraion forecasts.\n",
    "\n",
    "### Highlights\n",
    "The key features of an end to end run are: \n",
    "* Setup: _this was concerned with setting up the conda environment, which remains the same_\n",
    "* [Download](#Download): we explore the source data downloaded under the `/data/` folder, reusable across multiple environments\n",
    "* [Process](#Process): we explore the preprocessing outputs in the `/processed/` folder, which can be fed to models directly or further processed into IceNet datasets\n",
    "* [Train](#Train): we explore the outputs from the training process and ensemble runs, stored within `/results/networks/`\n",
    "* [Predict](#Predict): we explore the output from the prediction process and ensemble runs, stored within `/results/predict/`\n",
    "\n",
    "_This follows the same structure as the CLI demonstration notebook so that it's easy to follow step-by-step..._\n",
    "\n",
    "### Contributions\n",
    "#### Notebook\n",
    "James Byrne (author)\n",
    "\n",
    "__Please raise issues [in this repository](https://github.com/icenet-ai/icenet-notebooks/issues) to suggest updates to this notebook!__ \n",
    "\n",
    "Contact me at _jambyr \\<at\\> bas.ac.uk_ for anything else...\n",
    "\n",
    "#### Modelling codebase\n",
    "James Byrne (code author), Tom Andersson (science author)\n",
    "\n",
    "#### Modelling publications\n",
    "Andersson, T.R., Hosking, J.S., PÃ©rez-Ortiz, M. et al. Seasonal Arctic sea ice forecasting with probabilistic deep learning. Nat Commun 12, 5124 (2021). https://doi.org/10.1038/s41467-021-25257-4\n",
    "\n",
    "#### Involved organisations\n",
    "The Alan Turing Institute and British Antarctic Survey"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "For the purposes of python analysis we use and provide the following header libraries which are heavily utilised within the IceNet project and the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, json, os\n",
    "import datetime as dt\n",
    "import pandas as pd, xarray as xr, matplotlib.pyplot as plt\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download\n",
    "\n",
    "Downloading data using the icenet_data commands produces a dataset specific input data storage directory called `/data` whose source data can be reused across normalisation (`icenet_process*`) and dataset production (`icenet_dataset*`) runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of these directories (aside from masks) have consistent layouts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob(\"data/**/2020.nc\", recursive=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With masks being the only caveat. However, masks can be interacted with purely through the `Masks` class from `icenet2.data.sic.mask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob(\"data/masks/**/*.*\", recursive=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `siconca` variable files are source files for generating the masks that are not actually used after initial mask creation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing data source videos\n",
    "\n",
    "One of the easiest ways to inspect source data is to use the `icenet_video_data` command, which will output to `/plot/` in the run directory video(s) corresponding to the selected dataset, hemisphere, variable and year, or all of these items if run with: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!icenet_video_data --years 2020 era5,osisaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, we can display the videos right here in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "Video(\"plot/data_era5_south_tas.mp4\", embed=True, width=750)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equivalent can be run for any dataset under `/data/` with this command. The command also exposes numerous options allowing you to refine via the aforementioned items. Consult `-h` for more information.\n",
    "\n",
    "### Data storage structure\n",
    "\n",
    "The reason for this structure is that it applies consistency no matter how many different implementations of data downloaders and data processors are in place. The IceNet library (see next notebook) inherits this structure per-implementation from a common set of parents. Aside from making programmitically overriding and implementing new functionality easier, this __consistency means that plotting and analysis of the data stores becomes trivial__, aiding both research and production analysis of data all the way through the pipeline, however it's implemented.\n",
    "\n",
    "For example, looking at the southern hemisphere sea surface temperature in our example source datastore for the 1st January 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.plot.contourf(xr.open_dataset(\"data/era5/south/tas/2020.nc\").isel(time=0).tas, levels=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Against the sea ice for the same day is super intuitive to derive from the filesystem naming, by simply changing the respective dataset and variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.plot.contourf(xr.open_dataset(\"data/osisaf/south/siconca/2020.nc\").isel(time=0).ice_conc, levels=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, switching to the normalised versions (change to `/processed/`) and/or checking other datasets and/or globbing for datasets that can be opened with [`xarray.open_mfdataset`](https://xarray.pydata.org/en/stable/generated/xarray.open_mfdataset.html) is equally trivial thanks to this consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.plot.contourf(xr.open_dataarray(\"processed/notebook_data/osisaf/south/siconca/siconca_abs.nc\").isel(time=0), levels=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we'll see later, extending the library to incorporate additional source data simply adds further entries to the `/data` directory, with the implementations ultimately following a consistent approach to storing the data to make more complex analysis trivial.\n",
    "\n",
    "#### Dask example\n",
    "\n",
    "For example, needing to inspect the maximum values for sea surface temperature across all 1990's and 2000's data using dask, xarray and glob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from dask.distributed import Client\n",
    "dfs = glob.glob(\"data/era5/south/tos/19*.nc\") + glob.glob(\"data/era5/south/tos/20*.nc\")\n",
    "client = Client()\n",
    "ds = xr.open_mfdataset(dfs, combine=\"nested\", concat_dim=\"time\", parallel=True)\n",
    "a = ds.groupby(\"time.year\").max(\"time\").max((\"yc\", \"xc\"))\n",
    "m = a.compute()\n",
    "for y in m.year.values:\n",
    "    print(\"{} {:.2f}\".format(y, float(m.sel(year=y))))\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process\n",
    "\n",
    "There is a level of consistency (notwithstanding the masks and [this currently open issue for clarity](https://github.com/icenet-ai/icenet/issues/3)) when looking at the processed files. The key here is that the data is normalised as appropriate via the use of processors defined in `icenet.data.processors`. \n",
    "\n",
    "The associated normalisation/climatological parameters are then stored in an _identified_ processed data folder, with a corresponding `loader.name.json` configuration file which takes the form: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!cat loader.notebook_data.json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This configuration tracks the various outputs from the normalisation process for each processor used, ensuring that no source data is normalised or modified and can thus be reused across different date ranges easily. At the same time, the caching of this data allows for two additional benefits aside from the obvious separation of preprocessing from data usage. Firstly, the prenormalisation allows uncached datasets to be used directly for predictions and training if desirable and, secondly, it allows multiple datasets to be derived from a single normalisation run which with larger datasets can take a reasonable amount of compute to achieve.\n",
    "\n",
    "Finally, storing this in a machine and human readable format makes datasets relatively easy to inspect via the loader configuration when you forget what commands you preprocessed with!\n",
    "\n",
    "__Note that the deeper elements of the configuration file aren't shown for brevity...__\n",
    "\n",
    "### Producing preprocessed data videos\n",
    "\n",
    "As with data sources, normalised data is easily visualized at the command line by running the `icenet_video_data` command, where `-p` specifies path to the directory under `/processed/`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!icenet_video_data -p processed/notebook_data era5,osisaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "Video(\"plot/processed_notebook_data_era5_south_uas.mp4\", embed=True, width=750)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "Training outputs are stored in their respectively named folders using the name provided from the commands `icenet_train` or `run_train_ensemble` respectively. The contents of these folders differ slightly, based simply on the number of runs executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"results/networks\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from the single run provides two appropriately named files, the JSON of the history object from the run and the weights of the network after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob(\"results/networks/notebook_testrun/**\", recursive=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the ensemble outputs the same files across each individual run, distinguished by the seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob(\"results/networks/notebook_ensemble/**/*.h5\", recursive=True) + glob.glob(\"results/networks/notebook_ensemble/**/*.json\", recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/networks/notebook_ensemble/notebook_ensemble_45_history.json\") as fh:\n",
    "    history = json.load(fh)\n",
    "\n",
    "# Quick and dirty visualisation\n",
    "fig = plt.figure(figsize=(int(len(history.keys())/2) * 3, 15))\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "for i, k in enumerate(history.keys()):\n",
    "    ax = fig.add_subplot(int(len(history.keys())/2) + len(history.keys())%2, 2, i+1)\n",
    "\n",
    "    ax.plot(history[k].keys(), history[k].values())\n",
    "    ax.set_title(k)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that other outputs result, depending on arguments provided and configuration, from `icenet_train` and `run_icenet_ensemble`. Both tensorboard and WandB outputs can be provided and, in the case of the latter, automatically uploaded when using the CLI tools. The output files are also retained in the run folders, with the latter ensemble members being stored in the `/ensemble/<ensembleName>/<ensembleName>-<runNumber>` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"ensemble/notebook_ensemble/notebook_ensemble-0\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the mechanism (in this case SLURM on our HPC) used to run the ensemble, the log files provide the full output from the run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ensemble/notebook_ensemble/notebook_ensemble-0/train.5777508.node021.42.out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course in the case of individual runs using `icenet_train` this output will have been presented to stdout/stderr (the screen) whilst running..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "The training runs provide insight into the training of the network (using the CLI in a very simple fashion) but the predictions produce actual forecast output to be studied or utilised. This can be evaluated as befits the user in comparison to the original SIC data or any other source to validate the forecasts. **Obviously with our notebook network these won't be accurate** but in real use you'd be expecting to produce comparable forecasts with the physics based data used to train the network.\n",
    "\n",
    "All outputs for prediction runs using either `icenet_predict` or `run_predict_ensemble` are stored in `results/predict`. For our notebook test and ensemble runs we can see the folder structure is similar to the training outputs, with folders named using the identifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob(\"results/predict/**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"results/predict/example_south_ensemble_forecast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"results/predict/example_south_ensemble_forecast/notebook_ensemble.45\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction per-network folder contains output from the network for the inputs provided, with the dates being the forecast start date. These files correspond to the *original dates we provided in the first notebook*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat testdates.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `loader` are also contained `outputs` and `weights`. The former \"outputs\" are the generated outputs for the network that would've been used for training. Remember, that to produce a forecast we use an input linear trend SIC channel set, alongside the atmospheric and other data channels. The weights is the collection of sample weights associated to the input set. These are really provided for debugging purposes, but may also be of some analytical interest in some cases. \n",
    "\n",
    "With the run of `icenet_output` as shown in the first notebook, these numpy-saved outputs are converted to a CF-compliant NetCDF that can be forwarded on or usefully analysed. \n",
    "\n",
    "### Plotting a forecast\n",
    "\n",
    "The following snippet uses one of these NetCDF's for plotting a forecast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icenet.plotting.video import xarray_to_video as xvid\n",
    "from icenet.data.sic.mask import Masks\n",
    "\n",
    "ds = xr.open_dataset(\"results/predict/example_south_ensemble_forecast.nc\")\n",
    "land_mask = Masks(south=True, north=False).get_land_mask()\n",
    "ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_date = ds.time.values[0]\n",
    "print(forecast_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = ds.sic_mean.isel(time=0).drop_vars(\"time\").rename(dict(leadtime=\"time\"))\n",
    "fc['time'] = [pd.to_datetime(forecast_date) \\\n",
    "              + dt.timedelta(days=int(e)) for e in fc.time.values]\n",
    "\n",
    "anim = xvid(fc, 15, figsize=4, mask=land_mask)\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, with the size and training of the notebook dataset this is not a particularly useful forecast but the ease of generating a visual is hopefully apparent. Also, this segways nicely into the next notebook as we've started to introduce leverages methods and classes directly from the `icenet` API itself. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook we've explored the data assets that are stored based on the end to end run of the pipeline, hopefully enough to make the user aware of the structuring of the run directory when using either single-run or ensemble-based mechanisms of execution. Using illustrative but minimal data, we've highlighted the potential use of these assets to generate visual products and give insight into the processing that takes place. \n",
    "\n",
    "Those interested in running forecasts with a properly scaled training and prediction set of data should now be able to consider doing so using the CLI commands. However, the CLI commands **only expose an illustrative set of commands at present**, whereas leveraging the API directly affords far more flexibility. This is explored in the remaining notebooks: \n",
    "\n",
    "* [Library usage](03.library_usage.ipynb): understand how to programmatically perform an end to end run.\n",
    "* [Library extension](04.library_extension.ipynb): understand why and how to extend the IceNet library.\n",
    "\n",
    "## Version\n",
    "- IceNet Codebase: v0.2.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icenet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
